{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_bva = \"data/annotations/20180415_bva.json\"\n",
    "PATH_cyber = \"data/annotations/20180415_cyber_crime.json\"\n",
    "PATH_intellectual = \"data/annotations/20180415_intellectual_property.json\"\n",
    "PATH_scotus = \"data/annotations/20180415_scotus.json\"\n",
    "\n",
    "PATHS = [PATH_bva, PATH_cyber, PATH_intellectual, PATH_scotus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_PN(original, pred):\n",
    "    original = original.replace(\"\\n\",\" \").split()\n",
    "    pred = pred.split()\n",
    "\n",
    "    # print(original)\n",
    "    # print(pred)\n",
    "    \n",
    "    beggining = [0, 0, 0, 0] #TP, TN, FP, FN\n",
    "    end = [0, 0, 0, 0]\n",
    "    i_max = [0, 0, 0, 0]\n",
    "\n",
    "    if original[0] == pred[0]:\n",
    "        beggining[0]+=1\n",
    "        i_max[1]+=1\n",
    "        end[1]+=1\n",
    "\n",
    "    else:\n",
    "        beggining[2]+=1\n",
    "        i_max[3]+=1\n",
    "\n",
    "    if original[-1] == pred[-1]:\n",
    "        end[0]+=1\n",
    "        i_max[1]+=1\n",
    "        beggining[1]+=1\n",
    "\n",
    "    else:\n",
    "        end[2]+=1\n",
    "        i_max[3]+=1\n",
    "\n",
    "    change = False\n",
    "    for pos in range(len(original)):\n",
    "        # print(i_max[0], len(pred))\n",
    "        if i_max[0] == len(pred):\n",
    "            beggining[3] =0\n",
    "            break\n",
    "        \n",
    "        if original[pos] != pred[0]:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            change = True\n",
    "        # print(beggining, i_max, end)\n",
    "        i = [0, 0, 0, 0] #TP, TN, FP, FN\n",
    "        temp_beg = beggining\n",
    "        temp_end = end\n",
    "\n",
    "        tip = len(original) if original < pred else pred\n",
    "\n",
    "        \n",
    "        for nth, (x, y) in enumerate(zip(range(pos, len(original)), range(len(pred)))):\n",
    "            if original[x]==pred[y]:\n",
    "                i[0]+=1\n",
    "                temp_beg[1]+=1\n",
    "                temp_end[1]+=1\n",
    "\n",
    "            else:\n",
    "                i[2]+=1\n",
    "                temp_beg[1]+=1\n",
    "                if nth!=tip:\n",
    "                    temp_end[3]+=1\n",
    "\n",
    "\n",
    "        if i[0]>i_max[0]:\n",
    "            i_max = i\n",
    "            if temp_beg[3]==0 and pos!=0:\n",
    "                temp_beg[3]+=1\n",
    "\n",
    "        elif i[0]==i_max[0] and (i[2] == 0) :\n",
    "            i_max = i\n",
    "\n",
    "\n",
    "            beggining = temp_beg\n",
    "            end = temp_end\n",
    "\n",
    "    if len(original) < len(pred):\n",
    "        i_max[2] +=len(pred) - len(original)\n",
    "    if len(original) > len(pred):\n",
    "        i_max[3] += len(original) - len(pred)     \n",
    "        \n",
    "           \n",
    "\n",
    "    if not change:\n",
    "        i_max[2] = len(pred)-1\n",
    "        \n",
    "\n",
    "    return beggining, i_max, len(original), len(pred),  end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x):\n",
    "    if sum(x) == 0:\n",
    "        return 0\n",
    "    return (x[0]+x[1])/sum(x)\n",
    "\n",
    "def recall(x):  #TP, TN, FP, FN\n",
    "    if x[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[0]/(x[0]+x[3])\n",
    "\n",
    "def precision(x):\n",
    "    if x[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[0]/(x[0]+x[2])\n",
    "\n",
    "def f1_score(x):\n",
    "    if x[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[0]/(x[0] + 0.5*(x[2]+x[3]))\n",
    "\n",
    "def specificity(x):\n",
    "    if x[1] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[1]/(x[1] + x[2])\n",
    "\n",
    "def acc_recall_precision_f1(x):\n",
    "    acc, rec, prec, f1, specificity_  = 0, 0, 0, 0, 0\n",
    "    t = 0\n",
    "    for i in x:\n",
    "        acc = acc + accuracy(i)\n",
    "        rec = rec + recall(i)\n",
    "        prec = prec + precision(i)\n",
    "        f1 = f1 + f1_score(i)\n",
    "        specificity_ = specificity_ + specificity(i)\n",
    "        \n",
    "\n",
    "    return acc/len(x), rec/len(x), prec/len(x), f1/len(x), specificity_/len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_str(string):\n",
    "    return string.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\")\n",
    "\n",
    "def check_range(pointer_start, pointer_end, ranges):\n",
    "    intersection_dict = {}\n",
    "    for i in ranges:\n",
    "        if pointer_start>=i['start'] and pointer_end>=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [i['end'] - pointer_start, abs(i['start']-pointer_start)]\n",
    "\n",
    "        if pointer_start<=i['start'] and pointer_end>=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [i['end'] - i['start'], abs(i['start']-pointer_start)]\n",
    "        \n",
    "        if pointer_start>=i['start'] and pointer_end<=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [pointer_end - pointer_start, abs(i['start']-pointer_start)]\n",
    "\n",
    "        if pointer_start<=i['start'] and pointer_end<=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [pointer_end - i['start'], abs(i['start']-pointer_start)]\n",
    "\n",
    "    max_intersection_key = None\n",
    "    max_intersection_len = -1\n",
    "    max_intersection_start_dist = 1000000\n",
    "    \n",
    "    for i in intersection_dict.keys():\n",
    "        if intersection_dict[i][0]>max_intersection_len or (intersection_dict[i][0]==max_intersection_len and max_intersection_start_dist<intersection_dict[i][1]):\n",
    "            max_intersection_len =  intersection_dict[i][0]\n",
    "            max_intersection_key = i\n",
    "            max_intersection_start_dist = intersection_dict[i][1]\n",
    "\n",
    "    return max_intersection_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luima_sbd',\n",
       " 'pysbd_crf_analysis.ipynb',\n",
       " 'NeuralNetworks',\n",
       " 'data',\n",
       " 'punkt.ipynb',\n",
       " 'dataset_analysis.ipynb',\n",
       " '.git',\n",
       " '.gitignore',\n",
       " 'results',\n",
       " 'testing.ipynb']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_PN(original, pred):\n",
    "    original = original.replace(\"\\n\",\" \").split()\n",
    "    pred = pred.split()\n",
    "\n",
    "    # print(original)\n",
    "    # print(pred)\n",
    "    \n",
    "    beggining = [0, 0, 0, 0] #TP, TN, FP, FN\n",
    "    end = [0, 0, 0, 0]\n",
    "    i_max = [0, 0, 0, 0]\n",
    "\n",
    "    if original[0] == pred[0]:\n",
    "        beggining[0]+=1\n",
    "        i_max[1]+=1\n",
    "        end[1]+=1\n",
    "\n",
    "    else:\n",
    "        beggining[2]+=1\n",
    "        i_max[3]+=1\n",
    "\n",
    "    if original[-1] == pred[-1]:\n",
    "        end[0]+=1\n",
    "        i_max[1]+=1\n",
    "        beggining[1]+=1\n",
    "\n",
    "    else:\n",
    "        end[2]+=1\n",
    "        i_max[3]+=1\n",
    "\n",
    "    change = False\n",
    "    for pos in range(len(original)):\n",
    "        # print(i_max[0], len(pred))\n",
    "        if i_max[0] == len(pred):\n",
    "            beggining[3] =0\n",
    "            break\n",
    "        \n",
    "        if original[pos] != pred[0]:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            change = True\n",
    "        \n",
    "        i = [0, 0, 0, 0] #TP, TN, FP, FN\n",
    "        temp_beg = beggining\n",
    "        temp_end = end\n",
    "\n",
    "        tip = len(original) if original < pred else pred\n",
    "\n",
    "        for nth, (x, y) in enumerate(zip(range(pos, len(original)), range(len(pred)))):\n",
    "            if original[x]==pred[y]:\n",
    "                i[0]+=1\n",
    "                temp_beg[1]+=1\n",
    "                temp_end[1]+=1\n",
    "\n",
    "            else:\n",
    "                i[2]+=1\n",
    "                temp_beg[1]+=1\n",
    "                if nth!=tip:\n",
    "                    temp_end[3]+=1\n",
    "\n",
    "\n",
    "        if i[0]>i_max[0]:\n",
    "            i_max = i\n",
    "            if temp_beg[3]==0 and pos!=0:\n",
    "                temp_beg[3]+=1\n",
    "\n",
    "        elif i[0]==i_max[0] and (i[2] == 0) :\n",
    "            i_max = i\n",
    "\n",
    "\n",
    "            beggining = temp_beg\n",
    "            end = temp_end\n",
    "        \n",
    "\n",
    "    if not change:\n",
    "        i_max[2] = len(pred)-2\n",
    "\n",
    "    return beggining, i_max, len(original), len(pred),  end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "\n",
    "characters = list(' '+string.printable.replace(\" \",\"\"))\n",
    "characters.append('UNK')\n",
    "\n",
    "characters = {x:i for i, x in enumerate(characters)}\n",
    "\n",
    "window_size = 6\n",
    "def BIL_model(model, text):\n",
    "    device='cpu'\n",
    "    text = text.replace(\"\\r\",\"\\n\").replace(\"\\t\",\"\\n\")\n",
    "\n",
    "    x = []\n",
    "    offsets = []\n",
    "    \n",
    "    for pos, char in enumerate(text):\n",
    "        if char == \".\":\n",
    "            right = text[pos+1:pos+window_size+1]\n",
    "            left = text[pos-window_size-1:pos-1]\n",
    "            if len(right) == 0:\n",
    "                right = \"\\n\"+ \" \"*(window_size-1)\n",
    "            # elif right.replace(\".\",\"\")[0] == \"\\n\":\n",
    "            #     continue\n",
    "            # elif right[0] == \"\\n\":\n",
    "            #     right = \"\\n\"+ \" \"*(window_size-1)\n",
    "            right = right + \" \"*(window_size-len(right))\n",
    "            left = \" \"*(window_size-len(left)) + left\n",
    "\n",
    "            x.append([left, right])\n",
    "            offsets.append(pos)\n",
    "\n",
    "\n",
    "    inputs = []\n",
    "    for i in x:\n",
    "        temp = []\n",
    "        x_ = ''.join(i[0]) + ''.join(i[1])\n",
    "        for i in x_:\n",
    "            if i in characters:\n",
    "                temp.append(characters[i])\n",
    "\n",
    "            else:\n",
    "                temp.append(characters['UNK'])\n",
    "            \n",
    "        inputs.append(np.asarray(temp))\n",
    "\n",
    "    inputs = torch.IntTensor(np.asarray(inputs)).to(device)\n",
    "\n",
    "    pred = model(inputs)\n",
    "\n",
    "    pred = pred.cpu().detach().numpy().tolist()\n",
    "    pred_offsets = []\n",
    "\n",
    "    for each_pred in pred:\n",
    "        pred_offsets.append(round(each_pred[0]))\n",
    "\n",
    "    output = []\n",
    "    start = 0\n",
    "\n",
    "    for i,j in zip(offsets, pred_offsets):\n",
    "        if j == 1:\n",
    "            output.append(text[start:i+1])\n",
    "            start = i+1\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def BIL_TF_PN(original, pred):\n",
    "    original = original.replace(\"\\n\",\" \").split()\n",
    "    pred = pred.split()\n",
    "\n",
    "    # print(original)\n",
    "    # print(pred)\n",
    "    \n",
    "    beggining = [0, 0, 0, 0] #TP, TN, FP, FN\n",
    "    end = [0, 0, 0, 0]\n",
    "    i_max = [0, 0, 0, 0]\n",
    "\n",
    "    if original[0] == pred[0]:\n",
    "        beggining[0]+=1\n",
    "        i_max[1]+=1\n",
    "        end[1]+=1\n",
    "\n",
    "    else:\n",
    "        beggining[2]+=1\n",
    "        i_max[3]+=1\n",
    "\n",
    "    if original[-1] == pred[-1]:\n",
    "        end[0]+=1\n",
    "        i_max[1]+=1\n",
    "        beggining[1]+=1\n",
    "\n",
    "    else:\n",
    "        end[2]+=1\n",
    "        i_max[3]+=1\n",
    "\n",
    "    change = False\n",
    "    for pos in range(len(original)):\n",
    "        # print(i_max[0], len(pred))\n",
    "        if i_max[0] == len(pred):\n",
    "            beggining[3] =0\n",
    "            break\n",
    "        \n",
    "        if original[pos] != pred[0]:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            change = True\n",
    "        \n",
    "        i = [0, 0, 0, 0] #TP, TN, FP, FN\n",
    "        temp_beg = beggining\n",
    "        temp_end = end\n",
    "\n",
    "        tip = len(original) if original < pred else pred\n",
    "\n",
    "        for nth, (x, y) in enumerate(zip(range(pos, len(original)), range(len(pred)))):\n",
    "            if original[x]==pred[y]:\n",
    "                i[0]+=1\n",
    "                temp_beg[1]+=1\n",
    "                temp_end[1]+=1\n",
    "\n",
    "            else:\n",
    "                i[2]+=1\n",
    "                temp_beg[1]+=1\n",
    "                if nth!=tip:\n",
    "                    temp_end[3]+=1\n",
    "\n",
    "\n",
    "        if i[0]>i_max[0]:\n",
    "            i_max = i\n",
    "            if temp_beg[3]==0 and pos!=0:\n",
    "                temp_beg[3]+=1\n",
    "\n",
    "        elif i[0]==i_max[0] and (i[2] == 0) :\n",
    "            i_max = i\n",
    "\n",
    "\n",
    "            beggining = temp_beg\n",
    "            end = temp_end\n",
    "        \n",
    "\n",
    "    if not change:\n",
    "        i_max[2] = len(pred)-2\n",
    "\n",
    "    return beggining, i_max, len(original), len(pred),  end\n",
    "\n",
    "\n",
    "def raw_str(string):\n",
    "    return string.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\")\n",
    "\n",
    "def check_range(pointer_start, pointer_end, ranges):\n",
    "    intersection_dict = {}\n",
    "    for i in ranges:\n",
    "        if pointer_start>=i['start'] and pointer_end>=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [i['end'] - pointer_start, abs(i['start']-pointer_start)]\n",
    "\n",
    "        if pointer_start<=i['start'] and pointer_end>=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [i['end'] - i['start'], abs(i['start']-pointer_start)]\n",
    "        \n",
    "        if pointer_start>=i['start'] and pointer_end<=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [pointer_end - pointer_start, abs(i['start']-pointer_start)]\n",
    "\n",
    "        if pointer_start<=i['start'] and pointer_end<=i['end']:\n",
    "            intersection_dict[str(i['start'])+'-'+str(i['end'])] = [pointer_end - i['start'], abs(i['start']-pointer_start)]\n",
    "\n",
    "    max_intersection_key = None\n",
    "    max_intersection_len = -1\n",
    "    max_intersection_start_dist = 1000000\n",
    "    \n",
    "    for i in intersection_dict.keys():\n",
    "        if intersection_dict[i][0]>max_intersection_len or (intersection_dict[i][0]==max_intersection_len and max_intersection_start_dist<intersection_dict[i][1]):\n",
    "            max_intersection_len =  intersection_dict[i][0]\n",
    "            max_intersection_key = i\n",
    "            max_intersection_start_dist = intersection_dict[i][1]\n",
    "\n",
    "    return max_intersection_key\n",
    "\n",
    "\n",
    "def BIL_accuracy(x):\n",
    "    if sum(x) == 0:\n",
    "        return 0\n",
    "    return (x[0]+x[1])/sum(x)\n",
    "\n",
    "def BIL_recall(x):  #TP, TN, FP, FN\n",
    "    if x[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[0]/(x[0]+x[3])\n",
    "\n",
    "def BIL_precision(x):\n",
    "    if x[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[0]/(x[0]+x[2])\n",
    "\n",
    "def BIL_f1_score(x):\n",
    "    if x[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[0]/(x[0] + 0.5*(x[2]+x[3]))\n",
    "\n",
    "def BIL_specificity(x):\n",
    "    if x[1] == 0:\n",
    "        return 0\n",
    "\n",
    "    return x[1]/(x[1] + x[2])\n",
    "\n",
    "def BIL_acc_recall_precision_f1(x):\n",
    "    acc, rec, prec, f1, specificity_  = 0, 0, 0, 0, 0\n",
    "    t = 0\n",
    "    for i in x:\n",
    "        acc = acc + BIL_accuracy(i)\n",
    "        rec = rec + BIL_recall(i)\n",
    "        prec = prec + BIL_precision(i)\n",
    "        f1 = f1 + BIL_f1_score(i)\n",
    "        specificity_ = specificity_ + BIL_specificity(i)\n",
    "        \n",
    "\n",
    "    return acc/len(x), rec/len(x), prec/len(x), f1/len(x), specificity_/len(x)\n",
    "\n",
    "\n",
    "def BIL_results(model, timer=False):\n",
    "    results = {}\n",
    "    total_time = 0\n",
    "\n",
    "    for path_ in [PATH_cyber]:\n",
    "        dataset = json.load(open(path_, \"r\", encoding=\"utf8\"))\n",
    "        results[path_] = []\n",
    "        for doc in dataset:\n",
    "            x = dataset[doc]['text'].replace(\"\\r\",\"\\n\").replace(\"\\t\",\"\\n\")\n",
    "            y = []\n",
    "            for sentence in dataset[doc]['annotations']:\n",
    "                y.append(dataset[doc]['text'][sentence['start']:sentence['end']])\n",
    "\n",
    "            start_time = time.time()\n",
    "            pred = BIL_model(model, x)\n",
    "\n",
    "            if timer:\n",
    "                print(\"--- Model took %s seconds to predict ---\" % (time.time() - start_time))\n",
    "            \n",
    "            total_time = total_time + (time.time() - start_time)\n",
    "            # print(len(y), len(pred))\n",
    "\n",
    "\n",
    "            pointer = 0\n",
    "            mappings = []\n",
    "            filtred_pred = []\n",
    "\n",
    "            for pred_sentences in pred:\n",
    "                maped = check_range(pointer, pointer+len(pred_sentences), dataset[doc]['annotations'])\n",
    "                # if maped != None:\n",
    "                #     print(raw_str(pred_sentences), raw_str(dataset['59bd4ac35116540935ee6851']['text'][int(maped.split('-')[0]):int(maped.split('-')[1])]), sep=\" ====== \", end=\"\\n\\n\")\n",
    "\n",
    "                pointer+=len(pred_sentences)\n",
    "\n",
    "                pred_sentences = pred_sentences.replace(\"\\n\",\" \")\n",
    "\n",
    "                if maped is not None :\n",
    "                    mappings.append(dataset[doc]['text'][int(maped.split('-')[0]):int(maped.split('-')[1])])\n",
    "                    filtred_pred.append(pred_sentences)\n",
    "                    results[path_].append(BIL_TF_PN(mappings[-1], filtred_pred[-1]))\n",
    "\n",
    "    for paths in results:\n",
    "        B = []\n",
    "        I = []\n",
    "        L = []\n",
    "\n",
    "        for i in results[paths]:\n",
    "            B.append(i[0])\n",
    "            I.append(i[1])\n",
    "            L.append(i[-1])\n",
    "\n",
    "\n",
    "        print(f\"B : {BIL_acc_recall_precision_f1(B)}\")\n",
    "        print(f\"I : {BIL_acc_recall_precision_f1(I)}\")\n",
    "        print(f\"L : {BIL_acc_recall_precision_f1(L)}\\n\")\n",
    "\n",
    "        if timer:\n",
    "             print(f\"--- Model took a total of {total_time} seconds to predict all the documents ---\")\n",
    "\n",
    "        return BIL_acc_recall_precision_f1(B), BIL_acc_recall_precision_f1(I), BIL_acc_recall_precision_f1(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Embedding: 1-1                         [-1, 12, 128]             12,928\n",
      "├─LSTM: 1-2                              [-1, 12, 512]             790,528\n",
      "├─Dropout: 1-3                           [-1, 512]                 --\n",
      "├─Linear: 1-4                            [-1, 1]                   513\n",
      "==========================================================================================\n",
      "Total params: 803,969\n",
      "Trainable params: 803,969\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.80\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 3.07\n",
      "Estimated Total Size (MB): 3.13\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Embedding: 1-1                         [-1, 12, 128]             12,928\n",
       "├─LSTM: 1-2                              [-1, 12, 512]             790,528\n",
       "├─Dropout: 1-3                           [-1, 512]                 --\n",
       "├─Linear: 1-4                            [-1, 1]                   513\n",
       "==========================================================================================\n",
       "Total params: 803,969\n",
       "Trainable params: 803,969\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.80\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.06\n",
       "Params size (MB): 3.07\n",
       "Estimated Total Size (MB): 3.13\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "import os\n",
    "import json\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class bilstm_model_attn(nn.Module):\n",
    "    def __init__(self,hidden_size,n_layer,vocab_size,embedding_size):\n",
    "        super().__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        self.lstm_layer = nn.LSTM(embedding_size,hidden_size,n_layer,batch_first = True, bidirectional = True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(2*hidden_size,1)\n",
    "\n",
    "\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        hidden = final_state.view(-1, self.hidden_size * 2, 1)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "        return context, soft_attn_weights # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "\n",
    "    def forward(self,x):\n",
    "        # hidden = (torch.zeros((self.n_layer,x.shape[0],self.hidden_size)).to(self.device),torch.zeros((self.n_layer,x.shape[0],self.hidden_size)).to(self.device))\n",
    "        x = self.embedding_layer(x)\n",
    "        output, (h, final_cell_state) = self.lstm_layer(x)\n",
    "        final_hidden_state = torch.concat((h[0], h[1]), dim=1)\n",
    "        attn_output, attention = self.attention_net(output, final_hidden_state)\n",
    "        x = self.dropout(attn_output)\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "device = \"cpu\"\n",
    "model = bilstm_model_attn(256,1,len(characters), 128).to(device)\n",
    "\n",
    "import torchsummary\n",
    "torchsummary.summary(model, (12,), dtypes =[torch.LongTensor], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model took 0.07420778274536133 seconds to predict ---\n",
      "--- Model took 0.13851070404052734 seconds to predict ---\n",
      "--- Model took 0.05753159523010254 seconds to predict ---\n",
      "--- Model took 0.14737963676452637 seconds to predict ---\n",
      "--- Model took 0.08783984184265137 seconds to predict ---\n",
      "--- Model took 0.14676332473754883 seconds to predict ---\n",
      "--- Model took 0.0848231315612793 seconds to predict ---\n",
      "--- Model took 0.19522786140441895 seconds to predict ---\n",
      "--- Model took 0.06178998947143555 seconds to predict ---\n",
      "--- Model took 0.11026930809020996 seconds to predict ---\n",
      "--- Model took 0.10772395133972168 seconds to predict ---\n",
      "--- Model took 0.060060739517211914 seconds to predict ---\n",
      "--- Model took 0.08044981956481934 seconds to predict ---\n",
      "--- Model took 0.18143486976623535 seconds to predict ---\n",
      "--- Model took 0.0296480655670166 seconds to predict ---\n",
      "--- Model took 0.06705784797668457 seconds to predict ---\n",
      "--- Model took 0.04059100151062012 seconds to predict ---\n",
      "--- Model took 0.10089421272277832 seconds to predict ---\n",
      "--- Model took 0.11151957511901855 seconds to predict ---\n",
      "B : (0.40403849045498147, 0.16860986547085202, 0.16860986547085202, 0.16860986547085202, 0.41310428010842554)\n",
      "I : (0.36921027831352726, 0.4026905829596413, 0.36275096663896084, 0.37067555702908966, 0.0089589296253323)\n",
      "L : (0.4185604683442751, 0.17259758290670318, 0.1789237668161435, 0.1731838880217004, 0.34798312348098775)\n",
      "\n",
      "--- Model took a total of 1.8860726356506348 seconds to predict all the documents ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.40403849045498147,\n",
       "  0.16860986547085202,\n",
       "  0.16860986547085202,\n",
       "  0.16860986547085202,\n",
       "  0.41310428010842554),\n",
       " (0.36921027831352726,\n",
       "  0.4026905829596413,\n",
       "  0.36275096663896084,\n",
       "  0.37067555702908966,\n",
       "  0.0089589296253323),\n",
       " (0.4185604683442751,\n",
       "  0.17259758290670318,\n",
       "  0.1789237668161435,\n",
       "  0.1731838880217004,\n",
       "  0.34798312348098775))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIL_results(model, timer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aac6a9f6e038666d9c19347a5caa7968d43d22ebc276d6ab3e43c5d06786ff02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
